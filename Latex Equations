Basic stats:

Mean:
\bar{x} = \frac{\sum xf}{\sum f}

Median:
M = \frac{(\frac{n}{2})^{th} \ term + (\frac{n}{2}+1)^{th} \ term }{2}

Mean from density function:
E[X] = \int_{-\infty}^{\infty} xf(x)dx

Standard deviation:
\sigma = \sqrt{\frac{\sum f(x-\bar{x})^2}{n}}

Variance from density function:
\sigma^2 = Var(X) = E[X^2] - (E[X])^2


Marginal probability of X from f(x,y) is given as:
f_X(x) = \int_{-\infty}^{\infty}f(x,y)dy

Z score
z = \frac{x-\mu}{\sigma}

### Tests


Z tests 

One sample z test

z = \frac{\bar{x} - \mu_0}{\frac{\sigma}{\sqrt{n}}}


One proportion z test

z = \frac{\hat{p}-p_0}{\frac{\sqrt{p_0(1-p_0)}}{n}}

t tests

one sample t test

t= \frac{\bar{x} - \mu_0}{\frac{s}{\sqrt{n}}}

Two sample z test 
z = \frac{\bar{x}_1-\bar{x}_1-\Delta}{\sqrt{\frac{\sigma_1^2}{n_1} +\frac{\sigma_2^2}{n_2}}}




Chi-square test

\chi^2 =\frac{s^2}{\sigma^2}(n-1)

### Confidence itervals


Confidence Interval for z test
C.I = \bar{x}\pm z_{ci}\frac{\sigma}{\sqrt{n}}


Confidence interval for 2 sample  t test (similar for z test also)
CI = (\bar{x}_1-\bar{x}_2) \pm tS_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}

Where, S_p = \sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}

Confidence interval for proportion z test
C.I = \hat{p} \pm z_{critical}\sqrt{\frac{ \hat{p}(1- \hat{p})}{n}}

And, n can be given as 
n = \frac{z_{critical}^2 \times \hat{p}(1-\hat{p})}{E^2}

Chi- square for population variance.
\chi^2 = \frac{s^2}{\sigma_0^2}(N-1)


Poisson Distribution:

For a random variable  according to  Poisson distribution, probability of  is given by 

P(X=x) = \frac{e^{-\lambda}\lambda^x}{x!}

where \lambda is the mean number of occurrence of x


Binomial distribution.
P(x) = _{}^{n}\textrm{C}_x p^x q^{n-x}


Probability and Set Theory
P (A \cup B) = P(A) + P(B) - P(A \cap B)

Conditional probability
P(B|A) = \frac{P(B \cap A)}{P(A)}


Chebyshev's theorem:

According to Chebyshev's inequality theorem 

The maximum probability of a random variable X  deviated k standard deviation away from the mean \mu  is given by 

P(|X-\mu| \ge k\sigma) \le \frac{1}{k^2}

And, from this we can derive that 
P(\mu - k\sigma < X < \mu + k\sigma) > 1 - \frac{1}{k^2}
At least (1 - \frac{1}{k^2})\% of data from a distribution fall within k standard deviation from the mean \mu


Quartiles:
Q_1 = (\frac{n+1}{4})^{th} \ term



Regression Equations:


S_x = \sqrt{\frac{\sum (x-\bar{x})^2 }{n-1}  }

r = \frac{\sum ((x-\bar{x})(y-\bar{y}))}{\sqrt{\sum (x-\bar{x})^2\sum (y-\bar{y})^2}}

t value for correlation coefficient:
t = r \sqrt{\frac{df}{1-r^2}} \   \ \ \ \ \ where \  \ \  df = N- 2
